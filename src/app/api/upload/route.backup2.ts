import { NextRequest, NextResponse } from 'next/server'
import { writeFile, rm, mkdir } from 'fs/promises'
import { join } from 'path'
import { randomUUID } from 'crypto'
import { FileUtils } from '@/lib/file-utils'
import {
  processMultiFormatFile,
  MultiFormatFileProcessor,
} from '@/lib/file-processor-v2'
import { FileRepository } from '@/lib/file-repository'
import { getEmbeddingVectors } from '@/lib/langchain/embeddings'
import { addDocuments } from '@/lib/langchain/vectorstore'
import { Document } from '@langchain/core/documents'

export async function POST(request: NextRequest) {
  try {
    console.log('üì§ [MULTI-FORMAT UPLOAD] Processing file upload request')
    const formData = await request.formData()
    const file = formData.get('file') as File
    const testMode = formData.get('testMode') as string

    // Handle test mode
    if (testMode) {
      console.log(`üß™ [TEST MODE] Test mode enabled: ${testMode}`)
    }

    if (!file) {
      console.log('‚ùå [UPLOAD] No file found in formData')
      return NextResponse.json(
        { step: 'file_check', error: 'No file provided' },
        { status: 400 }
      )
    }

    console.log(
      `üìÅ [UPLOAD] Received file: ${file.name} (${file.size} bytes, ${file.type})`
    )

    // Enhanced validation with multi-format support
    const validation = FileUtils.validateFile({
      size: file.size,
      mimetype: file.type,
      originalname: file.name,
    })

    if (!validation.valid) {
      console.log(`‚ùå [UPLOAD] Validation failed: ${validation.error}`)
      return NextResponse.json(
        { step: 'validation', error: validation.error },
        { status: 400 }
      )
    }

    // Check if file format is supported by new multi-format system
    if (!MultiFormatFileProcessor.isFormatSupported(file.name, file.type)) {
      const supportedFormats = MultiFormatFileProcessor.getSupportedFormats()
      console.log(`‚ùå [UPLOAD] Unsupported file format: ${file.name}`)
      return NextResponse.json(
        {
          step: 'format_check',
          error: `Unsupported file format. Supported formats: ${supportedFormats.extensions.join(
            ', '
          )}`,
        },
        { status: 400 }
      )
    }

    console.log('‚úÖ [UPLOAD] File format supported by multi-format processor')

    // Create temporary directory for processing
    const processId = randomUUID()
    const uploadDir = join(
      process.cwd(),
      'uploads',
      'temp',
      'processing',
      processId
    )
    const filePath = join(uploadDir, file.name)

    // Create processing directory
    await mkdir(uploadDir, { recursive: true })
    console.log(`üìÅ [UPLOAD] Created temporary directory: ${uploadDir}`)

    // Save file to temporary location
    const bytes = await file.arrayBuffer()
    const buffer = Buffer.from(bytes)
    await writeFile(filePath, buffer)
    console.log(`üíæ [UPLOAD] File saved to: ${filePath}`)

    let processedFile: any // –í—Ä–µ–º–µ–Ω–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º any –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    try {
      // Process file with new multi-format system
      console.log(
        'üîÑ [MULTI-FORMAT] Processing file with enhanced processor...'
      )
      processedFile = await processMultiFormatFile(
        filePath,
        file.name,
        file.type
      )

      console.log(
        `‚úÖ [MULTI-FORMAT] File processed successfully:
        - Format: ${processedFile.metadata.format}
        - Processor: ${processedFile.metadata.processor}
        - Chunks: ${processedFile.chunks.length}
        - Hash: ${processedFile.hash.substring(0, 8)}...`
      )

      // Check for duplicates using file hash (skip in test mode)
      if (!testMode || testMode === 'normal') {
        try {
          const existingFile = await FileRepository.findByHash(
            processedFile.hash
          )
          if (existingFile) {
            console.log('‚ö†Ô∏è [UPLOAD] Duplicate file detected, cleaning up...')
            await rm(uploadDir, { recursive: true, force: true })

            return NextResponse.json({
              success: true,
              step: 'duplicate_check',
              message: 'File was already uploaded previously',
              isDuplicate: true,
              fileInfo: {
                name: file.name,
                hash: processedFile.hash,
                format: processedFile.metadata.format,
                existingData: existingFile,
              },
            })
          }
        } catch (dbError) {
          console.log(
            '‚ö†Ô∏è [UPLOAD] Database error during duplicate check:',
            dbError
          )
          // Continue processing even if DB is unavailable
        }
      } else {
        console.log('üß™ [TEST MODE] Skipping duplicate check for test mode')
      }

      console.log('üöÄ [UPLOAD] Processing new file - no duplicates found')
      // Create LangChain Documents from chunks for vector storage
      console.log('üìÑ [LANGCHAIN] Creating LangChain documents from chunks...')
      const documents = processedFile.chunks.map((chunk, index) => {
        return new Document({
          pageContent: chunk.content,
          metadata: {
            chunkIndex: index,
            fileName: file.name,
            fileHash: processedFile.hash,
            format: processedFile.metadata.format,
            processor: processedFile.metadata.processor,
            uploadDate: new Date().toISOString(),
            ...processedFile.metadata,
          },
        })
      })

      console.log(
        `üìä [LANGCHAIN] Created ${documents.length} LangChain documents`
      )

      // AGGRESSIVE: limit number of chunks to prevent API overload
      if (documents.length > 100) {
        console.warn(
          `üö® CRITICAL: Too many chunks (${documents.length}), limiting to 100 to prevent API overload`
        )
        documents.splice(100) // Keep only first 100 chunks for stability
      }

      // Add documents to vector store using LangChain (batch processing for large files)
      let vectorIds: string[] = []

      // Set timeout for the entire upload operation
      const uploadTimeout = setTimeout(() => {
        throw new Error('Upload operation timed out after 5 minutes')
      }, 5 * 60 * 1000) // 5 minutes timeout

      try {
        console.log(
          `üîó [QDRANT] Adding ${documents.length} documents to vector store...`
        )

        // Process in small batches of 20 to prevent API overload and crashes
        const batchSize = 20
        const allVectorIds: string[] = []

        for (let i = 0; i < documents.length; i += batchSize) {
          const batch = documents.slice(i, i + batchSize)
          console.log(
            `üì¶ [QDRANT] Processing batch ${
              Math.floor(i / batchSize) + 1
            }/${Math.ceil(documents.length / batchSize)} (${
              batch.length
            } documents)`
          )

          const batchVectorIds = await addDocuments(batch)
          allVectorIds.push(...(batchVectorIds || []))

          // Longer delay between batches to prevent rate limiting and server stress
          if (i + batchSize < documents.length) {
            await new Promise((resolve) => setTimeout(resolve, 1000)) // 1000ms delay
          }
        }

        vectorIds = allVectorIds
        console.log(
          `‚úÖ [QDRANT] Successfully added ${
            vectorIds?.length || 0
          } vectors to Qdrant`
        )

        // Clear timeout on success
        clearTimeout(uploadTimeout)
      } catch (qdrantError) {
        // Clear timeout on error
        clearTimeout(uploadTimeout)
        console.error(
          '‚ùå [QDRANT] Error adding documents to vector store:',
          qdrantError
        )
        vectorIds = [] // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        // Continue execution - we can still save file metadata
      }

      // Save file record to database
      try {
        const fileId = await FileRepository.createFile({
          filename: file.name,
          original_name: file.name,
          file_hash: processedFile.hash, // Use proper hash from processor
          file_size: file.size,
          mime_type: file.type || 'application/octet-stream',
          metadata: {
            ...processedFile.metadata,
            vectorIds:
              vectorIds && vectorIds.length > 0 ? vectorIds : undefined,
            chunksCount: processedFile.chunks.length,
          },
        })
        console.log(`üíæ [DATABASE] File record created with ID: ${fileId}`)

        // Update status to completed
        await FileRepository.updateStatus(fileId, 'completed')
        console.log(`‚úÖ [DATABASE] File processing status updated to completed`)
      } catch (dbError) {
        console.error('‚ùå [DATABASE] Error saving file record:', dbError)
        // Continue - vector data is already saved
      }

      // Clean up temporary files
      try {
        await rm(uploadDir, { recursive: true, force: true })
        console.log('üßπ [CLEANUP] Temporary files removed successfully')
      } catch (cleanupError) {
        console.warn(
          '‚ö†Ô∏è [CLEANUP] Error removing temporary files:',
          cleanupError
        )
        // Not critical, continue
      }

      // Return success response
      return NextResponse.json({
        success: true,
        step: 'completed',
        message: 'File processed and uploaded successfully',
        fileInfo: {
          name: file.name,
          hash: processedFile.hash,
          format: processedFile.metadata.format,
          processor: processedFile.metadata.processor,
          size: file.size,
          chunks: processedFile.chunks.length,
          vectorsCreated: vectorIds?.length || 0,
          title: processedFile.metadata.title,
        },
      })
    } catch (processingError) {
      console.error('‚ùå [PROCESSING] File processing failed:', processingError)

      // Clean up temporary files on error
      try {
        await rm(uploadDir, { recursive: true, force: true })
        console.log('üßπ [CLEANUP] Temporary files cleaned up after error')
      } catch (cleanupError) {
        console.warn(
          '‚ö†Ô∏è [CLEANUP] Failed to clean up temporary files:',
          cleanupError
        )
      }

      return NextResponse.json(
        {
          success: false,
          step: 'processing_error',
          error: 'File processing failed',
          details:
            processingError instanceof Error
              ? processingError.message
              : String(processingError),
          supportedFormats:
            MultiFormatFileProcessor.getSupportedFormats().extensions,
        },
        { status: 500 }
      )
    }
  } catch (error) {
    console.error('‚ùå [UPLOAD] General upload error:', error)

    return NextResponse.json(
      {
        success: false,
        step: 'general_error',
        error: 'Internal server error during file upload',
        details: error instanceof Error ? error.message : String(error),
      },
      { status: 500 }
    )
  }
}
