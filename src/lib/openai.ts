import { ChatMessage } from './types'

const OPENAI_API_KEY = process.env.OPENAI_API_KEY
const OPENAI_EMBEDDING_MODEL =
  process.env.OPENAI_EMBEDDING_MODEL || 'text-embedding-ada-002'
const OPENAI_CHAT_MODEL = process.env.OPENAI_CHAT_MODEL || 'gpt-3.5-turbo'

if (!OPENAI_API_KEY) {
  throw new Error('OPENAI_API_KEY is not set in environment variables')
}

// –í—Ä–µ–º–µ–Ω–Ω–∞—è –∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
function shouldUseMock(): boolean {
  return (
    process.env.NODE_ENV === 'development' && process.env.USE_MOCK === 'true'
  )
}

export async function getEmbedding(text: string): Promise<number[]> {
  console.log(
    `üîç getEmbedding –≤—ã–∑–≤–∞–Ω–∞ —Å —Ç–µ–∫—Å—Ç–æ–º –¥–ª–∏–Ω–æ–π ${text.length} —Å–∏–º–≤–æ–ª–æ–≤`
  )
  console.log(
    `üîß USE_MOCK=${process.env.USE_MOCK}, NODE_ENV=${process.env.NODE_ENV}`
  )

  if (shouldUseMock()) {
    // –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    console.log('Using mock embedding for:', text)

    // –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞
    const hash = text
      .toLowerCase()
      .split('')
      .reduce((acc, char) => {
        return acc + char.charCodeAt(0)
      }, 0)

    return Array.from({ length: 1536 }, (_, i) => {
      const seed = (hash + i * 31) % 1000
      return Math.sin(seed) * 0.5 // –ó–Ω–∞—á–µ–Ω–∏—è –æ—Ç -0.5 –¥–æ 0.5
    })
  }

  console.log(`üöÄ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI API –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞...`)

  const response = await fetch('https://api.openai.com/v1/embeddings', {
    method: 'POST',
    headers: {
      Authorization: `Bearer ${OPENAI_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      input: text,
      model: OPENAI_EMBEDDING_MODEL,
    }),
  })

  if (!response.ok) {
    const errorText = await response.text()
    console.error('OpenAI API Error Details:', {
      status: response.status,
      statusText: response.statusText,
      body: errorText,
    })
    throw new Error(
      `OpenAI API error: ${response.status} ${response.statusText} - ${errorText}`
    )
  }

  const data = await response.json()
  return data.data[0].embedding
}

export async function getChatCompletion(
  messages: ChatMessage[],
  context?: string
): Promise<string> {
  if (shouldUseMock()) {
    // –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    const lastMessage = messages[messages.length - 1]
    console.log('Using mock chat completion for:', lastMessage.content)

    if (context) {
      return `–û—Ç–ª–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å! "${lastMessage.content}"\n\n–ù–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏:\n\n${context}\n\n–≠—Ç–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –º–æ–∫-—Ä–µ–∂–∏–º–µ. –í —Ä–µ–∞–ª—å–Ω–æ–º —Ä–µ–∂–∏–º–µ –∑–¥–µ—Å—å –±—ã–ª –±—ã –æ—Ç–≤–µ—Ç –æ—Ç OpenAI GPT.`
    } else {
      return `–í–æ–ø—Ä–æ—Å: "${lastMessage.content}"\n\n–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –∑–∞–¥–∞—Ç—å –¥—Ä—É–≥–æ–π.\n\n–≠—Ç–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –º–æ–∫-—Ä–µ–∂–∏–º–µ.`
    }
  }

  const systemMessage: ChatMessage = {
    role: 'assistant',
    content: context
      ? `–¢—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ò—Å–ø–æ–ª—å–∑—É–π —Å–ª–µ–¥—É—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n\n${context}\n\n–û—Ç–≤–µ—á–∞–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º.`
      : '–¢—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.',
  }

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      Authorization: `Bearer ${OPENAI_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: OPENAI_CHAT_MODEL,
      messages: [systemMessage, ...messages],
      max_tokens: 1000,
      temperature: 0.7,
    }),
  })

  if (!response.ok) {
    const errorText = await response.text()
    console.error('OpenAI API Error Details:', {
      status: response.status,
      statusText: response.statusText,
      body: errorText,
    })
    throw new Error(
      `OpenAI API error: ${response.status} ${response.statusText} - ${errorText}`
    )
  }

  const data = await response.json()
  return data.choices[0].message.content
}
