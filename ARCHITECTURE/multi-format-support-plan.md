# üìÑ Multi-Format File Support Plan

## üéØ –¶–µ–ª—å: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

–†–∞—Å—à–∏—Ä–∏—Ç—å RAG —Å–∏—Å—Ç–µ–º—É –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ñ–æ—Ä–º–∞—Ç–∞–º–∏ —Ñ–∞–π–ª–æ–≤: PDF, TXT, FB2, EPUB, DOC, DOCX.

## üîç –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ

### **–ß—Ç–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —Å–µ–π—á–∞—Å:**
- ‚úÖ **PDF** - —á–µ—Ä–µ–∑ `pdf-parse` –±–∏–±–ª–∏–æ—Ç–µ–∫—É
- ‚ùå **TXT** - –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
- ‚ùå **FB2** - –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è 
- ‚ùå **EPUB** - –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
- ‚ùå **DOC** - –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
- ‚ùå **DOCX** - –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è

### **–ü—Ä–æ–±–ª–µ–º—ã:**
- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ—Å—Ç—å —Ç–æ–ª—å–∫–æ PDF —Ñ–æ—Ä–º–∞—Ç–æ–º
- –ú–Ω–æ–≥–æ –¥—É—Ö–æ–≤–Ω–æ–π –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã –≤ FB2/EPUB —Ñ–æ—Ä–º–∞—Ç–∞—Ö
- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —Ö–æ—Ç—è—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å Word –¥–æ–∫—É–º–µ–Ω—Ç—ã
- –ü—Ä–æ—Å—Ç—ã–µ TXT —Ñ–∞–π–ª—ã –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ

## üìö –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏

### **üìÑ PDF (—É–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)**
```typescript
import pdfParse from 'pdf-parse'
// –¢–µ–∫—É—â–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –æ—Å—Ç–∞–µ—Ç—Å—è
```

### **üìù TXT - Plain Text**
```typescript
// –ü—Ä–æ—Å—Ç–æ–µ —á—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
const content = await fs.readFile(filePath, 'utf-8')
// –¢—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ chunking –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
```

### **üìñ FB2 - FictionBook Format**
```bash
npm install xml2js
```
```typescript
import xml2js from 'xml2js'

// FB2 - —ç—Ç–æ XML —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã—Ö –∫–Ω–∏–≥
// –°—Ç—Ä—É–∫—Ç—É—Ä–∞: <FictionBook><body><section><p>text</p></section></body></FictionBook>
const extractTextFromFB2 = async (buffer: Buffer): Promise<string> => {
  const xml = buffer.toString('utf-8')
  const parser = new xml2js.Parser()
  const result = await parser.parseStringPromise(xml)
  
  // –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –≤—Å–µ—Ö –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
  const extractTextFromNode = (node: any): string => {
    if (typeof node === 'string') return node
    if (Array.isArray(node)) return node.map(extractTextFromNode).join(' ')
    if (node.p) return extractTextFromNode(node.p)
    if (node.section) return extractTextFromNode(node.section)
    return ''
  }
  
  return extractTextFromNode(result.FictionBook?.body)
}
```

### **üìö EPUB - Electronic Publication**
```bash
npm install epub2
```
```typescript
import EPub from 'epub2'

const extractTextFromEPUB = async (filePath: string): Promise<string> => {
  return new Promise((resolve, reject) => {
    const epub = new EPub(filePath)
    epub.on('end', () => {
      const chapters = epub.flow.map(chapter => chapter.id)
      let fullText = ''
      
      let processedChapters = 0
      chapters.forEach(chapterId => {
        epub.getChapter(chapterId, (error, text) => {
          if (error) return reject(error)
          
          // –£–¥–∞–ª—è–µ–º HTML —Ç–µ–≥–∏
          const cleanText = text.replace(/<[^>]*>/g, '').trim()
          fullText += cleanText + '\n\n'
          
          processedChapters++
          if (processedChapters === chapters.length) {
            resolve(fullText)
          }
        })
      })
    })
    
    epub.on('error', reject)
    epub.parse()
  })
}
```

### **üìÑ DOCX - Microsoft Word (–Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç)**
```bash
npm install mammoth
```
```typescript
import mammoth from 'mammoth'

const extractTextFromDOCX = async (buffer: Buffer): Promise<string> => {
  const result = await mammoth.extractRawText({ buffer })
  return result.value
}
```

### **üìÑ DOC - Microsoft Word (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç)**
```bash
npm install textract
```
```typescript
import textract from 'textract'

const extractTextFromDOC = async (filePath: string): Promise<string> => {
  return new Promise((resolve, reject) => {
    textract.fromFileWithPath(filePath, (error, text) => {
      if (error) return reject(error)
      resolve(text)
    })
  })
}
```

## üìã –ü–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### **Phase 1: –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π Document Processor (2-3 –¥–Ω—è)**

#### 1.1 –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
```bash
npm install xml2js epub2 mammoth textract
npm install @types/xml2js @types/textract
```

#### 1.2 –°–æ–∑–¥–∞–Ω–∏–µ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞
```typescript
// src/lib/document-processors.ts
export interface DocumentProcessor {
  supportedMimeTypes: string[]
  supportedExtensions: string[]
  extractText(filePath: string, buffer: Buffer): Promise<string>
  validateFile(buffer: Buffer): boolean
}

export class PDFProcessor implements DocumentProcessor {
  supportedMimeTypes = ['application/pdf']
  supportedExtensions = ['.pdf']
  
  async extractText(filePath: string, buffer: Buffer): Promise<string> {
    const pdfData = await pdfParse(buffer)
    return pdfData.text
  }
  
  validateFile(buffer: Buffer): boolean {
    return buffer.subarray(0, 4).toString() === '%PDF'
  }
}

export class TXTProcessor implements DocumentProcessor {
  supportedMimeTypes = ['text/plain']
  supportedExtensions = ['.txt']
  
  async extractText(filePath: string, buffer: Buffer): Promise<string> {
    return buffer.toString('utf-8')
  }
  
  validateFile(buffer: Buffer): boolean {
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –≤–∞–ª–∏–¥–Ω—ã–π UTF-8 —Ç–µ–∫—Å—Ç
    try {
      buffer.toString('utf-8')
      return true
    } catch {
      return false
    }
  }
}

export class FB2Processor implements DocumentProcessor {
  supportedMimeTypes = ['application/x-fictionbook+xml', 'text/xml']
  supportedExtensions = ['.fb2']
  
  async extractText(filePath: string, buffer: Buffer): Promise<string> {
    const xml = buffer.toString('utf-8')
    const parser = new xml2js.Parser()
    const result = await parser.parseStringPromise(xml)
    
    // –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    const title = result.FictionBook?.description?.[0]?.['title-info']?.[0]?.['book-title']?.[0]
    const author = result.FictionBook?.description?.[0]?.['title-info']?.[0]?.author?.[0]
    
    // –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
    const bodyText = this.extractTextFromNode(result.FictionBook?.body)
    
    return `${title ? `–ù–∞–∑–≤–∞–Ω–∏–µ: ${title}\n` : ''}${author ? `–ê–≤—Ç–æ—Ä: ${author['first-name']} ${author['last-name']}\n\n` : ''}${bodyText}`
  }
  
  private extractTextFromNode(node: any): string {
    if (typeof node === 'string') return node
    if (Array.isArray(node)) return node.map(n => this.extractTextFromNode(n)).join(' ')
    if (node?.p) return this.extractTextFromNode(node.p)
    if (node?.section) return this.extractTextFromNode(node.section)
    if (node?.title) return this.extractTextFromNode(node.title) + '\n'
    return ''
  }
  
  validateFile(buffer: Buffer): boolean {
    const content = buffer.toString('utf-8', 0, 1000) // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 1000 –±–∞–π—Ç
    return content.includes('<FictionBook') || content.includes('<?xml')
  }
}

export class EPUBProcessor implements DocumentProcessor {
  supportedMimeTypes = ['application/epub+zip']
  supportedExtensions = ['.epub']
  
  async extractText(filePath: string, buffer: Buffer): Promise<string> {
    // EPUB - —ç—Ç–æ ZIP –∞—Ä—Ö–∏–≤, –ø–æ—ç—Ç–æ–º—É —Ä–∞–±–æ—Ç–∞–µ–º —Å —Ñ–∞–π–ª–æ–º –Ω–∞–ø—Ä—è–º—É—é
    return new Promise((resolve, reject) => {
      const epub = new EPub(filePath)
      
      epub.on('end', () => {
        const chapters = epub.flow.map(chapter => chapter.id)
        let fullText = ''
        let processedChapters = 0
        
        if (chapters.length === 0) {
          return resolve('')
        }
        
        chapters.forEach(chapterId => {
          epub.getChapter(chapterId, (error, text) => {
            if (error) {
              console.warn(`Failed to extract chapter ${chapterId}:`, error)
            } else {
              const cleanText = text.replace(/<[^>]*>/g, '').trim()
              if (cleanText) {
                fullText += cleanText + '\n\n'
              }
            }
            
            processedChapters++
            if (processedChapters === chapters.length) {
              resolve(fullText)
            }
          })
        })
      })
      
      epub.on('error', reject)
      epub.parse()
    })
  }
  
  validateFile(buffer: Buffer): boolean {
    // EPUB —Ñ–∞–π–ª—ã –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å ZIP —Å–∏–≥–Ω–∞—Ç—É—Ä—ã
    return buffer.subarray(0, 4).toString('hex') === '504b0304'
  }
}

export class DOCXProcessor implements DocumentProcessor {
  supportedMimeTypes = ['application/vnd.openxmlformats-officedocument.wordprocessingml.document']
  supportedExtensions = ['.docx']
  
  async extractText(filePath: string, buffer: Buffer): Promise<string> {
    const result = await mammoth.extractRawText({ buffer })
    return result.value
  }
  
  validateFile(buffer: Buffer): boolean {
    // DOCX —Ñ–∞–π–ª—ã —ç—Ç–æ ZIP –∞—Ä—Ö–∏–≤—ã —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
    return buffer.subarray(0, 4).toString('hex') === '504b0304'
  }
}

export class DOCProcessor implements DocumentProcessor {
  supportedMimeTypes = ['application/msword']
  supportedExtensions = ['.doc']
  
  async extractText(filePath: string, buffer: Buffer): Promise<string> {
    return new Promise((resolve, reject) => {
      textract.fromFileWithPath(filePath, { preserveLineBreaks: true }, (error, text) => {
        if (error) return reject(error)
        resolve(text || '')
      })
    })
  }
  
  validateFile(buffer: Buffer): boolean {
    // DOC —Ñ–∞–π–ª—ã –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å OLE —Å–∏–≥–Ω–∞—Ç—É—Ä—ã
    const signature = buffer.subarray(0, 8).toString('hex')
    return signature === 'd0cf11e0a1b11ae1'
  }
}

// –§–∞–±—Ä–∏–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤
export class DocumentProcessorFactory {
  private processors: DocumentProcessor[] = [
    new PDFProcessor(),
    new TXTProcessor(),
    new FB2Processor(),
    new EPUBProcessor(),
    new DOCXProcessor(),
    new DOCProcessor(),
  ]
  
  getProcessor(fileName: string, mimeType?: string): DocumentProcessor | null {
    const extension = path.extname(fileName).toLowerCase()
    
    // –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –ø–æ MIME —Ç–∏–ø—É
    if (mimeType) {
      const processor = this.processors.find(p => 
        p.supportedMimeTypes.includes(mimeType)
      )
      if (processor) return processor
    }
    
    // –ó–∞—Ç–µ–º –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é —Ñ–∞–π–ª–∞
    const processor = this.processors.find(p => 
      p.supportedExtensions.includes(extension)
    )
    
    return processor || null
  }
  
  getSupportedExtensions(): string[] {
    return this.processors.flatMap(p => p.supportedExtensions)
  }
  
  getSupportedMimeTypes(): string[] {
    return this.processors.flatMap(p => p.supportedMimeTypes)
  }
}

export const documentProcessorFactory = new DocumentProcessorFactory()
```

#### 1.3 –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π file-processor
```typescript
// src/lib/file-processor-v3.ts (–æ–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
import { documentProcessorFactory } from './document-processors'
import { calculateFileHash, checkFileExists } from './file-hash'

export async function processUploadedFile(
  file: File, 
  uploadedBy: number
): Promise<{ 
  isDuplicate: boolean, 
  fileHash: string, 
  processedFileId?: number,
  format: string
}> {
  
  const buffer = Buffer.from(await file.arrayBuffer())
  const fileHash = calculateFileHash(buffer)
  
  // –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç
  const existingFile = await getFileByHash(fileHash)
  if (existingFile) {
    return {
      isDuplicate: true,
      fileHash,
      processedFileId: existingFile.id,
      format: existingFile.format
    }
  }
  
  // –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è —Ñ–∞–π–ª–∞
  const processor = documentProcessorFactory.getProcessor(file.name, file.type)
  if (!processor) {
    throw new Error(`Unsupported file format: ${file.name}`)
  }
  
  // –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ñ–∞–π–ª
  if (!processor.validateFile(buffer)) {
    throw new Error(`Invalid file format or corrupted file: ${file.name}`)
  }
  
  const format = path.extname(file.name).toLowerCase().substring(1)
  
  // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –ë–î
  const db = await database
  const result = await db.run(`
    INSERT INTO processed_files (
      file_hash, original_filename, file_size, mime_type, 
      processing_status, uploaded_by, format, metadata_json
    ) VALUES (?, ?, ?, ?, 'processing', ?, ?, ?)
  `, [
    fileHash, 
    file.name, 
    buffer.length, 
    file.type, 
    uploadedBy, 
    format,
    JSON.stringify({ processor: processor.constructor.name })
  ])
  
  const processedFileId = result.lastID as number
  
  try {
    // –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    const tempDir = path.join(process.cwd(), 'temp', 'processing', crypto.randomUUID())
    await fs.mkdir(tempDir, { recursive: true })
    const tempFilePath = path.join(tempDir, file.name)
    await fs.writeFile(tempFilePath, buffer)
    
    const startTime = Date.now()
    
    // –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏—Å–ø–æ–ª—å–∑—É—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    const extractedText = await processor.extractText(tempFilePath, buffer)
    
    if (!extractedText.trim()) {
      throw new Error('No text content extracted from file')
    }
    
    // –°–æ–∑–¥–∞–µ–º chunks
    const chunks = await createTextChunks(extractedText, {
      chunkSize: 1000,
      chunkOverlap: 200,
      format: format
    })
    
    // –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
    const embedResults = await createEmbeddingsForChunks(chunks, processedFileId, {
      format,
      originalFileName: file.name
    })
    
    const processingTime = Date.now() - startTime
    
    // –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
    await db.run(`
      UPDATE processed_files 
      SET processing_status = 'completed',
          chunks_created = ?,
          embeddings_created = ?,
          processing_time_ms = ?,
          processed_at = CURRENT_TIMESTAMP
      WHERE id = ?
    `, [chunks.length, embedResults.length, processingTime, processedFileId])
    
    // –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    await fs.rm(tempDir, { recursive: true, force: true })
    
    return {
      isDuplicate: false,
      fileHash,
      processedFileId,
      format
    }
    
  } catch (error) {
    // –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∏ –æ—á–∏—Å—Ç–∫–∞
    await db.run(`
      UPDATE processed_files 
      SET processing_status = 'failed',
          error_message = ?
      WHERE id = ?
    `, [error.message, processedFileId])
    
    try {
      await fs.rm(tempDir, { recursive: true, force: true })
    } catch {}
    
    throw error
  }
}

// –£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è chunks —Å —É—á–µ—Ç–æ–º —Ñ–æ—Ä–º–∞—Ç–∞
async function createTextChunks(text: string, options: {
  chunkSize: number,
  chunkOverlap: number,
  format: string
}): Promise<string[]> {
  
  // –î–ª—è —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–∞–∑–±–∏–≤–∫–∏
  switch (options.format) {
    case 'fb2':
    case 'epub':
      // –î–ª—è –∫–Ω–∏–≥ —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –≥–ª–∞–≤–∞–º/—Ä–∞–∑–¥–µ–ª–∞–º
      return splitByChapters(text, options)
      
    case 'docx':
    case 'doc':
      // –î–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º
      return splitByParagraphs(text, options)
      
    default:
      // –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –¥–ª—è PDF –∏ TXT
      return splitByTokens(text, options)
  }
}

function splitByChapters(text: string, options: any): string[] {
  // –ò—â–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –≥–ª–∞–≤
  const chapterMarkers = [
    /\n\s*–ì–ª–∞–≤–∞\s+\d+/gi,
    /\n\s*–ì–õ–ê–í–ê\s+\d+/gi,
    /\n\s*Chapter\s+\d+/gi,
    /\n\s*\d+\.\s*$/gm
  ]
  
  let chapters = [text]
  
  for (const marker of chapterMarkers) {
    const newChapters = []
    for (const chapter of chapters) {
      newChapters.push(...chapter.split(marker))
    }
    chapters = newChapters.filter(c => c.trim().length > 100) // –ú–∏–Ω–∏–º—É–º 100 —Å–∏–º–≤–æ–ª–æ–≤
  }
  
  // –ï—Å–ª–∏ –≥–ª–∞–≤—ã —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ, –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–±–∏–≤–∞–µ–º
  return chapters.flatMap(chapter => 
    chapter.length > options.chunkSize * 2 
      ? splitByTokens(chapter, options)
      : [chapter]
  )
}

function splitByParagraphs(text: string, options: any): string[] {
  const paragraphs = text.split(/\n\s*\n/).filter(p => p.trim().length > 50)
  const chunks = []
  let currentChunk = ''
  
  for (const paragraph of paragraphs) {
    if (currentChunk.length + paragraph.length > options.chunkSize) {
      if (currentChunk) chunks.push(currentChunk)
      currentChunk = paragraph
    } else {
      currentChunk += (currentChunk ? '\n\n' : '') + paragraph
    }
  }
  
  if (currentChunk) chunks.push(currentChunk)
  return chunks
}

function splitByTokens(text: string, options: any): string[] {
  // –°—É—â–µ—Å—Ç–≤—É—é—â–∞—è –ª–æ–≥–∏–∫–∞ —Ä–∞–∑–±–∏–≤–∫–∏
  const sentences = text.split(/[.!?]+/).filter(s => s.trim().length > 0)
  const chunks = []
  let currentChunk = ''
  
  for (const sentence of sentences) {
    if (currentChunk.length + sentence.length > options.chunkSize) {
      if (currentChunk) chunks.push(currentChunk)
      currentChunk = sentence
    } else {
      currentChunk += (currentChunk ? '. ' : '') + sentence
    }
  }
  
  if (currentChunk) chunks.push(currentChunk)
  return chunks
}
```

### **Phase 2: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ UI –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (1-2 –¥–Ω—è)**

#### 2.1 –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤
```typescript
// src/components/admin/FileUploadForm.tsx
'use client'

import { useState } from 'react'
import { documentProcessorFactory } from '@/lib/document-processors'

export function FileUploadForm() {
  const [dragActive, setDragActive] = useState(false)
  const [uploadStatus, setUploadStatus] = useState<'idle' | 'uploading' | 'success' | 'error'>('idle')
  
  const supportedExtensions = documentProcessorFactory.getSupportedExtensions()
  const supportedMimeTypes = documentProcessorFactory.getSupportedMimeTypes()

  const validateFile = (file: File): string | null => {
    const extension = '.' + file.name.split('.').pop()?.toLowerCase()
    
    if (!supportedExtensions.includes(extension)) {
      return `–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: ${supportedExtensions.join(', ')}`
    }
    
    if (file.size > 50 * 1024 * 1024) { // 50MB –ª–∏–º–∏—Ç
      return '–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 50MB'
    }
    
    return null
  }

  const handleFileUpload = async (file: File) => {
    const validationError = validateFile(file)
    if (validationError) {
      alert(validationError)
      return
    }
    
    setUploadStatus('uploading')
    
    const formData = new FormData()
    formData.append('file', file)
    
    try {
      const response = await fetch('/api/upload', {
        method: 'POST',
        body: formData
      })
      
      const result = await response.json()
      
      if (response.ok) {
        setUploadStatus('success')
        if (result.isDuplicate) {
          alert(`–§–∞–π–ª —É–∂–µ –±—ã–ª –∑–∞–≥—Ä—É–∂–µ–Ω —Ä–∞–Ω–µ–µ (—Ñ–æ—Ä–º–∞—Ç: ${result.format})`)
        } else {
          alert(`–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω (—Ñ–æ—Ä–º–∞—Ç: ${result.format})`)
        }
      } else {
        throw new Error(result.error || 'Upload failed')
      }
    } catch (error) {
      setUploadStatus('error')
      alert(`–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: ${error.message}`)
    }
  }

  return (
    <div className="space-y-4">
      <div className="text-sm text-gray-600">
        <p><strong>–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:</strong></p>
        <div className="flex flex-wrap gap-2 mt-2">
          {supportedExtensions.map(ext => (
            <span key={ext} className="px-2 py-1 bg-blue-100 text-blue-800 rounded text-xs">
              {ext.toUpperCase()}
            </span>
          ))}
        </div>
      </div>
      
      <div
        className={`border-2 border-dashed rounded-lg p-8 text-center transition-colors ${
          dragActive 
            ? 'border-blue-500 bg-blue-50' 
            : 'border-gray-300 hover:border-gray-400'
        }`}
        onDragEnter={() => setDragActive(true)}
        onDragLeave={() => setDragActive(false)}
        onDragOver={(e) => e.preventDefault()}
        onDrop={(e) => {
          e.preventDefault()
          setDragActive(false)
          const file = e.dataTransfer.files[0]
          if (file) handleFileUpload(file)
        }}
      >
        <input
          type="file"
          accept={supportedMimeTypes.join(',')}
          onChange={(e) => {
            const file = e.target.files?.[0]
            if (file) handleFileUpload(file)
          }}
          className="hidden"
          id="file-upload"
        />
        
        <label htmlFor="file-upload" className="cursor-pointer">
          <div className="space-y-2">
            <div className="text-4xl">üìÑ</div>
            <div>
              <p className="text-lg font-medium">–ü–µ—Ä–µ—Ç–∞—â–∏—Ç–µ —Ñ–∞–π–ª —Å—é–¥–∞ –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ –¥–ª—è –≤—ã–±–æ—Ä–∞</p>
              <p className="text-sm text-gray-500">
                PDF, TXT, FB2, EPUB, DOC, DOCX –¥–æ 50MB
              </p>
            </div>
          </div>
        </label>
        
        {uploadStatus === 'uploading' && (
          <div className="mt-4">
            <div className="inline-flex items-center gap-2 text-blue-600">
              <div className="w-4 h-4 border-2 border-blue-600 border-t-transparent rounded-full animate-spin"></div>
              –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞...
            </div>
          </div>
        )}
      </div>
    </div>
  )
}
```

#### 2.2 –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ñ–æ—Ä–º–∞—Ç–∞–º —Ñ–∞–π–ª–æ–≤
```typescript
// src/app/api/admin/files/stats-by-format/route.ts
export async function GET() {
  const db = await database
  
  const formatStats = await db.all(`
    SELECT 
      format,
      COUNT(*) as count,
      SUM(file_size) as total_size,
      AVG(processing_time_ms) as avg_processing_time,
      SUM(chunks_created) as total_chunks,
      COUNT(CASE WHEN processing_status = 'completed' THEN 1 END) as successful,
      COUNT(CASE WHEN processing_status = 'failed' THEN 1 END) as failed
    FROM processed_files 
    GROUP BY format
    ORDER BY count DESC
  `)
  
  return NextResponse.json({
    formats: formatStats.map(stat => ({
      ...stat,
      total_size_mb: Math.round(stat.total_size / 1024 / 1024 * 100) / 100,
      success_rate: stat.count > 0 ? Math.round(stat.successful / stat.count * 100) : 0
    }))
  })
}
```

### **Phase 3: LangChain.js –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –º—É–ª—å—Ç–∏-—Ñ–æ—Ä–º–∞—Ç–æ–º (1-2 –¥–Ω—è)**

#### 3.1 Document Loaders –¥–ª—è LangChain
```typescript
// src/lib/langchain/document-loaders.ts
import { Document } from "langchain/document"
import { BaseDocumentLoader } from "langchain/document_loaders/base"
import { documentProcessorFactory } from '../document-processors'

export class MultiFormatLoader extends BaseDocumentLoader {
  constructor(
    private filePath: string,
    private buffer: Buffer,
    private fileName: string,
    private mimeType?: string
  ) {
    super()
  }

  async load(): Promise<Document[]> {
    const processor = documentProcessorFactory.getProcessor(this.fileName, this.mimeType)
    
    if (!processor) {
      throw new Error(`Unsupported file format: ${this.fileName}`)
    }

    const text = await processor.extractText(this.filePath, this.buffer)
    
    const format = path.extname(this.fileName).toLowerCase().substring(1)
    
    return [
      new Document({
        pageContent: text,
        metadata: {
          source: this.fileName,
          format: format,
          size: this.buffer.length,
          processor: processor.constructor.name,
          extractedAt: new Date().toISOString()
        }
      })
    ]
  }
}

// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–æ–≤
export async function createDocumentFromFile(
  filePath: string, 
  buffer: Buffer, 
  fileName: string, 
  mimeType?: string
): Promise<Document[]> {
  const loader = new MultiFormatLoader(filePath, buffer, fileName, mimeType)
  return await loader.load()
}
```

## üìä –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### **üìö –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞:**
- **+500% —Ñ–æ—Ä–º–∞—Ç–æ–≤** - –ø–æ–¥–¥–µ—Ä–∂–∫–∞ 6 —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤ –≤–º–µ—Å—Ç–æ 1
- **üìñ –î—É—Ö–æ–≤–Ω–∞—è –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞** - FB2/EPUB —Ñ–æ—Ä–º–∞—Ç—ã –ø–æ–ø—É–ª—è—Ä–Ω—ã –≤ —ç—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏
- **üìÑ –û—Ñ–∏—Å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã** - DOC/DOCX –¥–ª—è –¥–µ–ª–æ–≤–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
- **üìù –ü—Ä–æ—Å—Ç—ã–µ —Ç–µ–∫—Å—Ç—ã** - TXT —Ñ–∞–π–ª—ã –¥–ª—è –∑–∞–º–µ—Ç–æ–∫ –∏ –≤—ã–ø–∏—Å–æ–∫

### **üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å:**
- **–í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–æ–≤** - –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–æ–≤
- **–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞** - –ª–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
- **–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π chunking** - —Ä–∞–∑–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤
- **–î–µ—Ç–∞–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞** - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ñ–æ—Ä–º–∞—Ç–∞–º

### **üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –æ–ø—ã—Ç:**
- **Drag & Drop** –¥–ª—è –≤—Å–µ—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
- **–í–∏–∑—É–∞–ª—å–Ω–∞—è –∏–Ω–¥–∏–∫–∞—Ü–∏—è** –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ç–∏–ø–æ–≤
- **–ü–æ–Ω—è—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏** –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤
- **–ü—Ä–æ–≥—Ä–µ—Å—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏** –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞

## ‚úÖ –ö—Ä–∏—Ç–µ—Ä–∏–∏ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏

- [ ] –í—Å–µ 6 —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è
- [ ] –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
- [ ] UI –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
- [ ] –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ –ø–æ –∫–∞–∂–¥–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
- [ ] LangChain.js –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω —Å –º—É–ª—å—Ç–∏-—Ñ–æ—Ä–º–∞—Ç–Ω—ã–º–∏ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞–º–∏
- [ ] –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤

## üîÆ –ë—É–¥—É—â–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è

### **–ü–ª–∞–Ω–∏—Ä—É–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:**
- **RTF** - Rich Text Format
- **ODT** - OpenDocument Text
- **HTML** - –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã
- **MD** - Markdown —Ñ–∞–π–ª—ã
- **CSV/XLSX** - —Ç–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏

### **–£–ª—É—á—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:**
- **OCR –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö PDF** - –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- **–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–±–ª–∏—Ü** - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
- **–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö** - –∞–≤—Ç–æ—Ä, –¥–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è, —Ç–µ–≥–∏
- **–ú–Ω–æ–≥–æ—è–∑—ã—á–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞** - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞

---
*Multi-format support –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç RAG —Å–∏—Å—Ç–µ–º—É –≤ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ª—é–±—ã–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º.*