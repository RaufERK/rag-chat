#!/usr/bin/env tsx

import fs from 'fs/promises'
import path from 'path'
import { OptimizedTextSplitter } from '../src/lib/text-splitter-optimized'
import { TextSplitter } from '../src/lib/text-splitter'

/**
 * –¢–µ—Å—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å—Ç–∞—Ä–æ–≥–æ –∏ –Ω–æ–≤–æ–≥–æ —á–∞–Ω–∫–∏–Ω–≥–∞
 */

async function testChunkingComparison() {
  try {
    console.log('üß™ Testing chunking optimization...\n')

    // –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
    const testFiles = [
      'test-data/txt/sample.txt',
      'test-data/doc/test_file_doc.doc',
    ]

    for (const testFile of testFiles) {
      try {
        console.log(`üìÑ Testing file: ${testFile}`)

        let text: string

        if (testFile.endsWith('.txt')) {
          text = await fs.readFile(path.join(process.cwd(), testFile), 'utf-8')
        } else {
          // –î–ª—è DOC —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
          const { documentProcessorFactory } = await import(
            '../src/lib/document-processors-clean'
          )
          const processor = documentProcessorFactory.getProcessor(testFile)
          if (!processor) {
            console.log(`‚ùå No processor for ${testFile}`)
            continue
          }

          const buffer = await fs.readFile(path.join(process.cwd(), testFile))
          text = await processor.extractText('', buffer)
        }

        console.log(`üìä Original text: ${text.length} characters`)

        // –°—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥
        console.log('\nüî∏ OLD CHUNKING METHOD:')
        const startOld = Date.now()
        const oldChunks = TextSplitter.splitText(text)
        const timeOld = Date.now() - startOld

        console.log(`  - Chunks: ${oldChunks.length}`)
        console.log(
          `  - Average size: ${Math.round(
            oldChunks.reduce((sum, c) => sum + c.content.length, 0) /
              oldChunks.length
          )} chars`
        )
        console.log(`  - Processing time: ${timeOld}ms`)

        // –ù–æ–≤—ã–π –º–µ—Ç–æ–¥
        console.log('\nüîπ NEW OPTIMIZED METHOD:')
        const startNew = Date.now()
        const newChunks = OptimizedTextSplitter.splitTextOptimized(text, {
          chunkSize: 1000, // —Ç–æ–∫–µ–Ω–æ–≤
          chunkOverlap: 200, // —Ç–æ–∫–µ–Ω–æ–≤
          preserveStructure: true,
        })
        const timeNew = Date.now() - startNew

        console.log(`  - Chunks: ${newChunks.length}`)
        console.log(
          `  - Average size: ${Math.round(
            newChunks.reduce((sum, c) => sum + c.content.length, 0) /
              newChunks.length
          )} chars`
        )
        console.log(
          `  - Average tokens: ${Math.round(
            newChunks.reduce((sum, c) => sum + (c.tokenCount || 0), 0) /
              newChunks.length
          )}`
        )
        console.log(`  - Processing time: ${timeNew}ms`)

        // –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
        console.log('\nüìà COMPARISON:')
        console.log(
          `  - Chunk reduction: ${oldChunks.length} ‚Üí ${
            newChunks.length
          } (${Math.round(
            (1 - newChunks.length / oldChunks.length) * 100
          )}% fewer)`
        )
        console.log(
          `  - Speed improvement: ${timeOld}ms ‚Üí ${timeNew}ms (${
            timeNew < timeOld ? 'faster' : 'slower'
          })`
        )
        console.log(
          `  - Estimated API calls reduction: ${Math.round(
            (1 - newChunks.length / oldChunks.length) * 100
          )}%`
        )

        // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤
        console.log('\nüìù SAMPLE CHUNKS:')
        console.log('OLD METHOD (first 2 chunks):')
        oldChunks.slice(0, 2).forEach((chunk, i) => {
          console.log(
            `  ${i + 1}. "${chunk.content.substring(0, 100)}..." (${
              chunk.content.length
            } chars)`
          )
        })

        console.log('\nNEW METHOD (first 2 chunks):')
        newChunks.slice(0, 2).forEach((chunk, i) => {
          console.log(
            `  ${i + 1}. "${chunk.content.substring(0, 100)}..." (${
              chunk.content.length
            } chars, ~${chunk.tokenCount} tokens)`
          )
        })

        console.log('\n' + '='.repeat(80) + '\n')
      } catch (error) {
        console.error(`‚ùå Error testing ${testFile}:`, error.message)
      }
    }

    // Cleanup
    OptimizedTextSplitter.cleanup()

    console.log('üéâ Chunking comparison test completed!')
    console.log('\nüí° Key benefits of optimized chunking:')
    console.log('  - Fewer chunks = fewer API calls = faster embedding')
    console.log('  - Token-based sizing = better OpenAI compatibility')
    console.log('  - Structure preservation = better context retention')
    console.log('  - Configurable via admin panel')
  } catch (error) {
    console.error('‚ùå Test failed:', error)
    process.exit(1)
  }
}

if (require.main === module) {
  testChunkingComparison()
}
